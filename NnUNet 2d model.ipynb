{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:38:45.342675Z",
     "start_time": "2024-06-14T15:38:45.340813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess"
   ],
   "id": "a401cba4b2d4093c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:55:49.562734Z",
     "start_time": "2024-06-14T15:55:49.560633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure nnunetv2 is in the Python path\n",
    "nnunetv2_path = r'/alsxdata/ItamarAndDafna/FinalProjectCode/FinalProject/nnUNet/nnUNet/nnunetv2'\n",
    "if nnunetv2_path not in sys.path:\n",
    "    sys.path.append(nnunetv2_path)"
   ],
   "id": "b03c56f886399afe",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:55:53.946565Z",
     "start_time": "2024-06-14T15:55:52.409928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nnUNet_raw = r'/alsxdata/ItamarAndDafna/FinalProjectCode/FinalProject/nnUNet/nnUNet_raw'\n",
    "nnUNet_preprocessed = r'/alsxdata/ItamarAndDafna/FinalProjectCode/FinalProject/nnUNet/nnUNet_preprocessed'\n",
    "nnUNet_results = r'/alsxdata/ItamarAndDafna/FinalProjectCode/FinalProject/nnUNet/nnUNet_results'\n",
    "\n",
    "dataset_name = 'Dataset001_1530640M1'\n",
    "dataset_id= '001'\n",
    "\n",
    "# Define paths to the preprocessed data and results directory\n",
    "imagesTr_dir = os.path.join(nnUNet_raw, dataset_name, 'imagesTr')\n",
    "imagesTs_dir = os.path.join(nnUNet_raw, dataset_name, 'imagesTs')\n",
    "labelsTr_dir = os.path.join(nnUNet_raw, dataset_name, 'labelsTr')\n",
    "preprocessed_dir = os.path.join(nnUNet_preprocessed, dataset_name)\n",
    "results_dir = os.path.join(nnUNet_results, dataset_name)\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Run nnU-Net preprocessing\n",
    "preprocess_command = [\n",
    "    \"nnUNetv2_plan_and_preprocess\",\n",
    "    \"-d\", \"001\",  # Dataset ID, this should match with your dataset JSON settings\n",
    "    \"--verify_dataset_integrity\"\n",
    "]\n",
    "\n",
    "print(\"Running nnU-Net preprocessing...\")\n",
    "subprocess.run(preprocess_command, check=True)\n",
    "\n"
   ],
   "id": "5bffbf82ad3c47f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running nnU-Net preprocessing...\n",
      "nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "Fingerprint extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dafkad@bm.technion.ac.il/.local/bin/nnUNetv2_plan_and_preprocess\", line 8, in <module>\n",
      "    sys.exit(plan_and_preprocess_entry())\n",
      "  File \"/alsxdata/ItamarAndDafna/nnunetv2/experiment_planning/plan_and_preprocess_entrypoints.py\", line 184, in plan_and_preprocess_entry\n",
      "    extract_fingerprints(args.d, args.fpe, args.npfp, args.verify_dataset_integrity, args.clean, args.verbose)\n",
      "  File \"/alsxdata/ItamarAndDafna/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 47, in extract_fingerprints\n",
      "    extract_fingerprint_dataset(d, fingerprint_extractor_class, num_processes, check_dataset_integrity, clean,\n",
      "  File \"/alsxdata/ItamarAndDafna/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 26, in extract_fingerprint_dataset\n",
      "    dataset_name = convert_id_to_dataset_name(dataset_id)\n",
      "  File \"/alsxdata/ItamarAndDafna/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n",
      "    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n",
      "RuntimeError: Could not find a dataset with the ID 1. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n",
      "nnUNet_preprocessed=None\n",
      "nnUNet_results=None\n",
      "nnUNet_raw=None\n",
      "If something is not right, adapt your environment variables.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['nnUNetv2_plan_and_preprocess', '-d', '001', '--verify_dataset_integrity']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 27\u001B[0m\n\u001B[1;32m     20\u001B[0m preprocess_command \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnnUNetv2_plan_and_preprocess\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m001\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# Dataset ID, this should match with your dataset JSON settings\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--verify_dataset_integrity\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     24\u001B[0m ]\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRunning nnU-Net preprocessing...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 27\u001B[0m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocess_command\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/alsxdata/envs/ItamarAndDafnaEnv/lib/python3.10/subprocess.py:526\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[1;32m    524\u001B[0m     retcode \u001B[38;5;241m=\u001B[39m process\u001B[38;5;241m.\u001B[39mpoll()\n\u001B[1;32m    525\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check \u001B[38;5;129;01mand\u001B[39;00m retcode:\n\u001B[0;32m--> 526\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(retcode, process\u001B[38;5;241m.\u001B[39margs,\n\u001B[1;32m    527\u001B[0m                                  output\u001B[38;5;241m=\u001B[39mstdout, stderr\u001B[38;5;241m=\u001B[39mstderr)\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m CompletedProcess(process\u001B[38;5;241m.\u001B[39margs, retcode, stdout, stderr)\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command '['nnUNetv2_plan_and_preprocess', '-d', '001', '--verify_dataset_integrity']' returned non-zero exit status 1."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "1d816fa1-22da-4c98-a874-1331fc3d333b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T08:02:38.826100Z",
     "start_time": "2024-06-10T08:02:38.808466Z"
    }
   },
   "source": [
    "def plan_and_preprocess(task_name):\n",
    "    # Convert task name to task ID\n",
    "    task_id = convert_id_to_task_name(task_name)\n",
    "\n",
    "    # Get default configuration\n",
    "    plans_file, folder_with_preprocessed_data, task_name, output_folder_name = get_default_configuration(\n",
    "        2, task_id, 'default_plans_identifier', 'default_data_identifier')\n",
    "\n",
    "    # Create experiment planner\n",
    "    experiment_planner = ExperimentPlanner2DUNet(folder_with_preprocessed_data, plans_file)\n",
    "    experiment_planner.plan_experiment()\n",
    "\n",
    "    # Preprocess the data\n",
    "    preprocessor = GenericPreprocessor()\n",
    "    preprocessor.run_plans(output_folder_name)\n",
    "\n",
    "def train_model(task_name, fold):\n",
    "    # Set up trainer\n",
    "    trainer = nnUNetTrainerV2(\n",
    "        2, fold, output_folder=os.path.join(RESULTS_FOLDER, task_name, '2d'))\n",
    "    trainer.initialize(training=True)\n",
    "\n",
    "    # Load dataset\n",
    "    trainer.load_dataset()\n",
    "\n",
    "    # Plan and preprocess the data\n",
    "    trainer.plan_experiment()\n",
    "\n",
    "    # Train the model\n",
    "    trainer.run_training()\n",
    "\n",
    "def evaluate_model(task_name, fold):\n",
    "    # Load model and checkpoint files\n",
    "    model, params = load_model_and_checkpoint_files(os.path.join(RESULTS_FOLDER, task_name, '2d'), fold)\n",
    "    \n",
    "    # Predict from folder\n",
    "    predict_from_folder(\n",
    "        model, os.path.join(nnUNet_raw, task_name, 'imagesTs'), \n",
    "        os.path.join(RESULTS_FOLDER, task_name, 'predictions'), params)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    task_name = 'Dataset001_1530640M1'\n",
    "    fold = 0  # You can change this to run different folds\n",
    "\n",
    "    # Plan and preprocess the dataset\n",
    "    plan_and_preprocess(task_name)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(task_name, fold)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(task_name, fold)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RESULTS_FOLDER' from 'nnunetv2.paths' (/home/dafkad@bm.technion.ac.il/.local/lib/python3.10/site-packages/nnunetv2/paths.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Import necessary modules from nnunetv2\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnnunetv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpaths\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nnUNet_raw, RESULTS_FOLDER\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnnunetv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_default_configuration\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnnunetv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExperimentPlanner2DUNet\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'RESULTS_FOLDER' from 'nnunetv2.paths' (/home/dafkad@bm.technion.ac.il/.local/lib/python3.10/site-packages/nnunetv2/paths.py)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T19:49:58.800789Z",
     "start_time": "2024-06-06T19:49:58.631707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import subprocess\n",
    "# \n",
    "# def run_nnunet_training(dataset_id, fold):\n",
    "#     command = [\n",
    "#         r'C:\\Users\\dafka\\FinalProject\\nnUNet\\nnUNet_raw\\Dataset001_1530640M1\\imagesTr',\n",
    "#         '2d', # or '2d', '3d_lowres', '3d_fullres', '3d_cascade_fullres' depending on your setup\n",
    "#         f'nnUNetTrainerV2',\n",
    "#         str(dataset_id),\n",
    "#         str(fold)\n",
    "#     ]\n",
    "#     subprocess.run(command, check=True)\n",
    "# \n",
    "# # Define the dataset ID or name properly\n",
    "# dataset_name='Dataset001_1530640M1' \n",
    "# \n",
    "# # Train the model for all folds (usually 5 folds: 0 to 4)\n",
    "# for fold in range(5):\n",
    "#     run_nnunet_training(dataset_name, fold=fold)  # Assuming your dataset ID is 1\n"
   ],
   "id": "a195b9b5-923f-49ef-b1f8-231616d4f201",
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Train the model for all folds (usually 5 folds: 0 to 4)\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m fold \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m---> 18\u001B[0m     \u001B[43mrun_nnunet_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfold\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Assuming your dataset ID is 1\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[17], line 11\u001B[0m, in \u001B[0;36mrun_nnunet_training\u001B[1;34m(dataset_id, fold)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_nnunet_training\u001B[39m(dataset_id, fold):\n\u001B[0;32m      4\u001B[0m     command \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdafka\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mFinalProject\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mnnUNet\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mnnUNet_raw\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mDataset001_1530640M1\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mimagesTr\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      6\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2d\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;66;03m# or '2d', '3d_lowres', '3d_fullres', '3d_cascade_fullres' depending on your setup\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28mstr\u001B[39m(fold)\n\u001B[0;32m     10\u001B[0m     ]\n\u001B[1;32m---> 11\u001B[0m     \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:548\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    545\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstdout\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m PIPE\n\u001B[0;32m    546\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstderr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m PIPE\n\u001B[1;32m--> 548\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpopenargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m process:\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    550\u001B[0m         stdout, stderr \u001B[38;5;241m=\u001B[39m process\u001B[38;5;241m.\u001B[39mcommunicate(\u001B[38;5;28minput\u001B[39m, timeout\u001B[38;5;241m=\u001B[39mtimeout)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1026\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001B[0m\n\u001B[0;32m   1022\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_mode:\n\u001B[0;32m   1023\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[0;32m   1024\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m-> 1026\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1027\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1028\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1029\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1030\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1031\u001B[0m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1032\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1034\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprocess_group\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m   1036\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdin, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr)):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1538\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# Start the process\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1538\u001B[0m     hp, ht, pid, tid \u001B[38;5;241m=\u001B[39m \u001B[43m_winapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCreateProcess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1539\u001B[0m \u001B[43m                             \u001B[49m\u001B[38;5;66;43;03m# no special security\u001B[39;49;00m\n\u001B[0;32m   1540\u001B[0m \u001B[43m                             \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1541\u001B[0m \u001B[43m                             \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1542\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[43m                             \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1544\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1545\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1546\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1547\u001B[0m     \u001B[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001B[39;00m\n\u001B[0;32m   1548\u001B[0m     \u001B[38;5;66;03m# handles that only the child should have open.  You need\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;66;03m# pipe will not close when the child process exits and the\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m     \u001B[38;5;66;03m# ReadFile will hang.\u001B[39;00m\n\u001B[0;32m   1553\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001B[0;32m   1554\u001B[0m                          c2pread, c2pwrite,\n\u001B[0;32m   1555\u001B[0m                          errread, errwrite)\n",
      "\u001B[1;31mPermissionError\u001B[0m: [WinError 5] Access is denied"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:35:36.855710Z",
     "start_time": "2024-06-08T12:35:36.691698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up the nnUNet environment variables\n",
    "os.environ['nnUNet_raw'] = r'C:\\Users\\dafka\\FinalProject\\nnUNet\\nnUNet_raw'\n",
    "os.environ['nnUNet_preprocessed'] = r'C:\\Users\\dafka\\FinalProject\\nnUNet\\nnUNet_preprocessed'\n",
    "os.environ['RESULTS_FOLDER'] = r'C:\\Users\\dafka\\FinalProject\\nnUNet\\nnUNet_trained_models'\n",
    "\n",
    "def plan_and_preprocess(task_name):\n",
    "    # Convert task name to task ID\n",
    "    task_id = convert_id_to_task_name(task_name)\n",
    "\n",
    "    # Get default configuration\n",
    "    plans_file, folder_with_preprocessed_data, task_name, output_folder_name = get_default_configuration(\n",
    "        2, task_id, default_plans_identifier, default_data_identifier)\n",
    "\n",
    "    # Create experiment planner\n",
    "    experiment_planner = ExperimentPlanner2DUNet(folder_with_preprocessed_data, plans_file)\n",
    "    experiment_planner.plan_experiment()\n",
    "\n",
    "    # Preprocess the data\n",
    "    preprocessor = GenericPreprocessor()\n",
    "    preprocessor.run_plans(output_folder_name)\n",
    "\n",
    "def train_model(task_name, fold):\n",
    "    # Set up trainer\n",
    "    trainer = nnUNetTrainerV2(\n",
    "        2, fold, output_folder=os.path.join(RESULTS_FOLDER, task_name, '2d'))\n",
    "    trainer.initialize(training=True)\n",
    "\n",
    "    # Load dataset\n",
    "    trainer.load_dataset()\n",
    "\n",
    "    # Plan and preprocess the data\n",
    "    trainer.plan_experiment()\n",
    "\n",
    "    # Train the model\n",
    "    trainer.run_training()\n",
    "\n",
    "def evaluate_model(task_name, fold):\n",
    "    # Load model and checkpoint files\n",
    "    model, params = load_model_and_checkpoint_files(os.path.join(RESULTS_FOLDER, task_name, '2d'), fold)\n",
    "    \n",
    "    # Predict from folder\n",
    "    predict_from_folder(\n",
    "        model, os.path.join(nnUNet_raw, task_name, 'imagesTs'), \n",
    "        os.path.join(RESULTS_FOLDER, task_name, 'predictions'), params)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    task_name = 'Dataset001_1530640M1'\n",
    "    fold = 0  # You can change this to run different folds\n",
    "\n",
    "    # Plan and preprocess the dataset\n",
    "    plan_and_preprocess(task_name)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(task_name, fold)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(task_name, fold)"
   ],
   "id": "5f993b76-d99b-44f0-a514-4ce1f20fb8f3",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_id_to_task_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 51\u001B[0m\n\u001B[0;32m     48\u001B[0m fold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# You can change this to run different folds\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# Plan and preprocess the dataset\u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m \u001B[43mplan_and_preprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m     54\u001B[0m train_model(task_name, fold)\n",
      "Cell \u001B[1;32mIn[37], line 8\u001B[0m, in \u001B[0;36mplan_and_preprocess\u001B[1;34m(task_name)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplan_and_preprocess\u001B[39m(task_name):\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# Convert task name to task ID\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m     task_id \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_id_to_task_name\u001B[49m(task_name)\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# Get default configuration\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     plans_file, folder_with_preprocessed_data, task_name, output_folder_name \u001B[38;5;241m=\u001B[39m get_default_configuration(\n\u001B[0;32m     12\u001B[0m         \u001B[38;5;241m2\u001B[39m, task_id, default_plans_identifier, default_data_identifier)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'convert_id_to_task_name' is not defined"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
